# start with small complexity parameter
tree <- rpart(class ~ .,
data=train, method="class",
control = rpart.control(cp=0.001))
rpart.plot(tree)
printcp(tree)
plotcp(tree)
# choose the best one (minimizes xerror)
bestcp = tree$cptable[ which.min(tree$cptable[,"xerror"]), "CP" ]
tree.pruned <- prune(tree, cp=bestcp)
rpart.plot(tree.pruned, extra=3)
tree.conf <- confusionMatrix(test$class, predict(tree.pruned, test, type="class") , "0")
tree.acc <- diagnosticErrors(tree.conf)[1]
naive.acc
tree.acc
cross = 10
folds <- cut( seq(1,length(sample(ids))), breaks=cross, labels=F )
forest.pruned <- randomForest(as.factor(class) ~ ., data=train, mtry=15, ntree=500)
print(forest.pruned) # view results
varImpPlot(forest, sort=T, main="Importance")
varImpPlot(forest.pruned, sort=T, main="Importance")
forest.conf <- confusionMatrix(test$class, predict(forest.pruned, test, type="class"), "0")
diagnosticErrors(forest.conf)[1]
## radial basis
SVM.radial <- svm(as.factor(class) ~ ., data=train,
kernel = "radial")
SVMtuned.conf <- confusionMatrix(test$class, predict(SVM.tuned, test, type="class"), "0")
SVMradial.conf <- confusionMatrix(test$class, predict(SVM.radial, test, type="class"), "0")
diagnosticErrors(SVMradial.conf)[1]
tree.pred <- predict(tree.pruned, test, type="class")[,2]
tree.pruned
predict(tree.pruned, test, type="class")
predict(tree.pruned, test, type="class")[,2]
predict(tree.pruned, test, type="class")[2,]
predict(tree.pruned, test, type="class")[2]
tree.pred <- predict(tree.pruned, test, type="class")
tree.prediction <- prediction(tree.pred, test$class)
?prediction
test$class[:10]
test$class[1:10]
tree.pred[1:10]
tree.pred[,1]
tree.pred[,2]
tree.pred[2]
tree.pred[1]
str(tree.pred)
class(tree.pred)
tree.pred <- predict(tree.pruned, test$class, type="class")
tree.pred <- predict(tree.pruned, test$class, type="prob")
tree.pred <- predict(tree.pruned, test$class, type="class")
tree.pred <- predict(tree.pruned, as.factor(test$class), type="class")
tree.pred <- predict(tree.pruned, as.factor(test$class), type="prob")
tree.pred <- predict(tree.pruned, test[.-36], type="class")
tree.pred <- predict(tree.pruned, test[,-36], type="class")
tree.prediction <- prediction(tree.pred, test$class)
tree.prediction <- prediction(tree.pred, as.factor(test$class))
tree.pred[1:10]
tree.pred <- predict(tree.pruned, test[,-36], type="class")[,2]
tree.pred <- predict(tree.pruned, test[,-36], type="class")
tree.pred <- predict(tree.pruned, test[,-36], type="prob")
tree.pred[1:10]
tree.pred <- predict(tree.pruned, test[,-36], type="prob")[,2]
tree.pred[1:10]
tree.prediction <- prediction(tree.pred, as.factor(test$class))
tree.prediction[1:10]
tree.prediction
tree.perf <- performance(tree.prediction, measure = "tpr", x.measure = "fpr")
plot(tree.perf,
main="ROC curve: Tree",
colorize = T)
forest.pred <- predict(forest.pruned, test[,-36], type="prob")[,2]
forest.prediction <- prediction(forest.pred, test$class)
forest.perf <- performance(forest.prediction, measure = "tpr", x.measure = "fpr")
plot(forest.prediction,
main="ROC curve: Forest",
colorize = T)
plot(forest.perf,
main="ROC curve: Forest",
colorize = T)
tree.pred <- predict(tree.pruned, test[,-36], type="prob")[,2]
tree.prediction <- prediction(tree.pred, test$class)
tree.perf <- performance(tree.prediction, measure = "tpr", x.measure = "fpr")
plot(tree.perf,
main="ROC curve: Tree",
colorize = T)
forest.pred <- predict(forest.pruned, test[,-36], type="prob")[,2]
forest.prediction <- prediction(forest.pred, test$class)
forest.perf <- performance(forest.prediction, measure = "tpr", x.measure = "fpr")
plot(forest.perf,
main="ROC curve: Forest",
colorize = T)
SVM.pred <- predict(SVM.pruned, test, type="prob")[,2]
SVM.pred <- predict(SVM.radial, test[,-36], type="prob")[,2]
SVM.pred <- predict(SVM.radial, test[,-36], type="prob")
SVM.pred
SVM.pred <- predict(SVM.radial, test, type="prob")
SVM.pred
SVM.pred <- predict(SVM.radial, test, type="class")
SVM.prediction <- prediction(SVM.pred, test$class)
SVM.pred <- predict(SVM.radial, test, type="prob")
SVM.prediction <- prediction(SVM.pred, test$class)
SVM.perf <- performance(SVM.pred, measure = "tpr", x.measure = "fpr")
SVM.pred
length(SVM.pred)
length(test$class)
SVM.prediction <- prediction(SVM.pred, test$class)
forest.pred
SVM.pred
SVM.pred <- predict(SVM.radial, test, type="prob")[,2]
SVM.pred <- predict(SVM.radial, test[,36], type="prob")[,2]
SVM.pred <- predict(SVM.radial, test[,-36], type="prob")[,2]
SVM.pred <- predict(SVM.radial, test[,-36], type="prob")
SVM.pred
SVM.pred[,2]
?attributes
fitted.1 <- attributes(predict(SVM.radial, test, type ="response", decision.values=TRUE))$decision.values
pred.1 <- prediction(fitted.1,test$class, label.ordering = c("No","Yes") )
test$class
pred.1 <- prediction(fitted.1, test$class, label.ordering = c("0","1") )
perf.1 <- performance(pred.1, measure = "tpr", x.measure = "fpr")
plot(perf.1,
main="ROC curve: SVM",
colorize = T)
fitted.1 <- attributes(predict(SVM.radial, test, type ="response", decision.values=TRUE))$decision.values
pred.1 <- prediction(fitted.1, test$class, label.ordering = c("1","0") )
perf.1 <- performance(pred.1, measure = "tpr", x.measure = "fpr")
plot(perf.1,
main="ROC curve: SVM",
colorize = T)
diagnosticErrors(SVMradial.conf)[1]
SVMradial.conf
SVM.fitted <- attributes(predict(SVM.radial, test, type ="response", decision.values=TRUE))$decision.values
SVM.pred <- prediction(SVM.fitted, test$class)
SVM.perf <- performance(SVM.pred, measure = "tpr", x.measure = "fpr")
plot(SVM.perf,
main="ROC curve: SVM",
colorize = T)
SVM.pred <- prediction(SVM.fitted, test$class, label.ordering = c("1","0") )
SVM.perf <- performance(SVM.pred, measure = "tpr", x.measure = "fpr")
plot(SVM.perf,
main="ROC curve: SVM",
colorize = T)
SVM.fitted <- predict(SVM.radial, test, type ="response", decision.values=TRUE)
SVM.pred <- prediction(SVM.fitted, test$class, label.ordering = c("1","0") )
SVM.fitted <- attributes(predict(SVM.radial, test[,36], type ="response", decision.values=TRUE))$decision.values
SVM.fitted <- attributes(predict(SVM.radial, test, type ="response", decision.values=TRUE))$decision.values
SVM.fitted <- predict(SVM.radial, test, type ="response", decision.values=TRUE)
SVM.pred <- prediction(SVM.fitted, test$class, label.ordering = c("1","0") )
SVM.fitted
SVM.fitted$decision.values
SVM.fitted <- predict(SVM.radial, test, type ="response")
SVM.pred <- prediction(SVM.fitted, test$class, label.ordering = c("1","0") )
))$decision.values
SVM.fitted <- attributes(predict(SVM.radial, test, type ="response", decision.values=TRUE))$decision.values
SVM.pred <- prediction(SVM.fitted, test$class, label.ordering = c("1","0") )
SVM.perf <- performance(SVM.pred, measure = "tpr", x.measure = "fpr")
plot(SVM.perf,
main="ROC curve: SVM",
colorize = T)
plot(forest.perf,
main="ROC curve: Forest",
colorize = T)
#random classifier
abline(a = 0, b = 1)
forest.pred
naive.pred
naive.prediction <- prediction(naive.pred, test$class)
naive.perf <- performance(naive.prediction, measure = "tpr", x.measure = "fpr")
plot(naive.perf,
main="ROC curve: Tree",
colorize = T)
tree.perf
naive.perf
tree.prediction
naive.prediction
naive.pred <- rep(0, nrow(test))
class(naive.pred)
class(tree.pred)
naive.prediction <- prediction(naive.pred, test$class)
naive.perf <- performance(naive.prediction, measure = "tpr", x.measure = "fpr")
plot(naive.perf,
main="ROC curve: Tree",
colorize = T)
plot(naive.perf,
main="ROC curve: Tree")
## decision trees
message("\nAUC-- DT")
tree.auc <- performance(tree.prediction, measure = "auc")
tree.auc.final <- round(tree.auc@y.values[[1]], 3)
tree.auc.final
plot(tree.roc,
main="ROC curve: Tree",
colorize = T)
tree.roc <- performance(tree.prediction, measure = "tpr", x.measure = "fpr")
plot(tree.roc,
main="ROC curve: Tree",
colorize = T)
tree.auc <- performance(tree.prediction, measure = "auc")
tree.auc.final <- round(tree.auc@y.values[[1]], 3)
round(tree.auc@y.values[[1]], 3)
forest.roc <- performance(forest.prediction, measure = "tpr", x.measure = "fpr")
plot(forest.roc,
main="ROC curve: Forest",
colorize = T)
forest.auc <- performance(forest.prediction, measure = "auc")
round(forest.auc@y.values[[1]], 3)
SVM.roc <- performance(SVM.pred, measure = "tpr", x.measure = "fpr")
plot(SVM.roc,
main="ROC curve: SVM",
colorize = T)
SVM.auc <- performance(SVM.prediction, measure = "auc")
SVM.prediction <- prediction(SVM.fitted, test$class, label.ordering = c("1","0") )
SVM.roc <- performance(SVM.prediction, measure = "tpr", x.measure = "fpr")
plot(SVM.roc,
main="ROC curve: SVM",
colorize = T)
SVM.auc <- performance(SVM.prediction, measure = "auc")
round(SVM.auc@y.values[[1]], 3)
#random classifier
abline(a = 0, b = 1)
abline(forest.roc,
main="ROC curve: Forest",
colorize = T)
plot(naive.perf,
main="ROC curve: Tree")
plot(tree.roc,
main="ROC curve: Tree",
add=T,
colorize = T)
plot(tree.roc,
main="ROC curve: Tree",
colorize = T)
plot(forest.roc,
main="ROC curve: Forest",
add=T,
colorize = T)
plot(SVM.roc,
main="ROC curve: SVM",
add=T,
colorize = T)
naive.roc <- performance(naive.prediction, measure = "tpr", x.measure = "fpr")
plot(naive.roc, add=T)
rm(list=ls())
library(data.table) # fread()
library(ggplot2) # nice boxplots
library(rpart) # tree models
library(rpart.plot) # nice tree graphs
library(glmnet) # logistic regression
library(randomForest) #random forest
library(e1071) # SVM
library(ROCR)		# ROC curves
library(crossval)   # model evaluation
data <- fread(file='plr.dataset.B.development.csv', header=T, sep="\t")
data <- as.data.frame(data)
sum(is.na(data)) # clean data ^^
features <- colnames(data)
features
str(data)
summary(data)
ids = levels(factor(data$protein_id))
# number of ids
length(ids)
# percentage of points with and without ligandibility prop
classTable <- table(data$protein_id, data$class, dnn = c("protein id", "Able to ligand"))
rowSegments <-  rowSums(classTable)
classTable <- round(classTable*100 / rowSums(classTable), digits=2)
classTable <- cbind(classTable, rowSegments)
colnames(classTable) <- c('No', 'Yes', 'Segments')
classTable
rm(rowSegments)
# (voluntary) ligand_distance distribution among proteins
gg <- ggplot(data, aes(x=factor(protein_id),
y=ligand_distance))
gg + geom_boxplot(notch=T, varwidth=T,
fill = "green", colour = "black",
outlier.colour = "red")
# preparing modeling data - ridding off protein ids
dataModel <- data[,-1]
colnames(dataModel)
train <- fread(file='plr.dataset.B.development.csv', header=T, sep="\t")
rm(list=ls())
train <- fread(file='plr.dataset.B.development.csv', header=T, sep="\t")
train <- as.data.frame(data)
train <- as.data.frame(train)
rm(list=ls())
train <- fread(file='plr.dataset.B.development.csv', header=T, sep="\t")
train <- as.data.frame(train)
features <- colnames(train)
str(train)
summary(train)
test <- fread(file='plr.dataset.B.test.blind.csv', header=T, sep="\t")
test <- as.data.frame(test)
colnames(test)
ids = levels(factor(train$protein_id))
levels(factor(test$protein_id))
rm(ids)
train.ids <- levels(factor(train$protein_id))
test.ids <- levels(factor(test$protein_id))
# number of ids
length(train.ids)
rm(list=ls())
library(data.table) # fread()
library(ggplot2) # nice boxplots
library(rpart) # tree models
library(rpart.plot) # nice tree graphs
library(glmnet) # logistic regression
library(randomForest) #random forest
library(e1071) # SVM
library(ROCR)		# ROC curves
library(crossval)   # model evaluation
data <- fread(file='plr.dataset.B.development.csv', header=T, sep="\t")
data <- as.data.frame(data)
features <- colnames(data)
features <- colnames(data[,-1])
str(data)
summary(data)
ids <- levels(factor(data$protein_id))
# number of ids
length(ids)
# percentage of points with and without ligandibility prop
classTable <- table(data$protein_id, data$class, dnn = c("protein id", "Able to ligand"))
rowSegments <-  rowSums(classTable)
classTable <- round(classTable*100 / rowSums(classTable), digits=2)
classTable <- cbind(classTable, rowSegments)
colnames(classTable) <- c('No', 'Yes', 'Segments')
classTable
classTable <- cbind(classTable, rowSegments. , dnn = c("protein id", "Able to ligand"))
# percentage of points with and without ligandibility prop
classTable <- table(data$protein_id, data$class, dnn = c("protein id", "Able to ligand"))
classTable
rowSegments <-  rowSums(classTable)
classTable <- round(classTable*100 / rowSums(classTable), digits=2)
classTable <- cbind(rowSegments, classTable)
classTable
colnames(classTable) <- c('Segments', 'No', 'Yes')
classTable
rm(rowSegments)
function summ(a,b) {
return a+b
}
summ <- function(a,b) {
a+b
}
summ(2,3)
summ <- function(a,b) {
a+b, a-b
}
summ <- function(a,b) {
c(a+b, a-b)
}
summ(2,3)
result <- summ(2,3)
result
class(result)
c(x,y) <- summ(2,3)
x,y <- summ(2,3)
list[x,y] <- summ(2,3)
rm(list=ls())
library(data.table) # fread()
library(ggplot2) # nice boxplots
library(rpart) # tree models
library(rpart.plot) # nice tree graphs
library(glmnet) # logistic regression
library(randomForest) #random forest
library(e1071) # SVM
library(ROCR)		# ROC curves
library(crossval)   # model evaluation
data <- fread(file='plr.dataset.B.development.csv', header=T, sep="\t")
data <- as.data.frame(data)
features <- colnames(data[,-1])
str(data)
summary(data)
ids <- levels(factor(data$protein_id))
# number of ids
length(ids)
# percentage of points with and without ligandibility prop
classTable <- table(data$protein_id, data$class, dnn = c("protein id", "Able to ligand"))
rowSegments <-  rowSums(classTable)
classTable <- round(classTable*100 / rowSums(classTable), digits=2)
classTable <- cbind(rowSegments, classTable)
colnames(classTable) <- c('Segments', 'No', 'Yes')
classTable
rm(rowSegments)
major <- "0"
naive.pred <- rep(major, nrow(data))
naive.conf <- confusionMatrix(data$class, naive.pred, "0")
naive.acc <- diagnosticErrors(naive.conf)[1]
set.seed(666)
i=5
indices <- which(folds==i)
folds <- cut( seq(1,length(sample(ids))), breaks=cross, labels=F )
cross = 10
folds <- cut( seq(1,length(sample(ids))), breaks=cross, labels=F )
indices <- which(folds==i)
set.seed(i*666)
cross.test <- subset( data[, -1], data$protein_id %in% ids[indices])
cross.train <- data [ !(row.names(data) %in% row.names(cross.test)), -1]
cross.train <- cross.train[sample(nrow(cross.train)), ]
# Random forest with default values
forest <- randomForest(as.factor(class) ~ .,
data=cross.train )
plot(forest, ylim=c(-1e-2,0.05))
print(forest) # view results
forest.conf <- confusionMatrix(cross.test$class, predict(forest, cross.train, type="class"), "0")
forest.conf
install.packages("rmarkdown")
library(rmarkdown)
sample(10)
sample(10, size = 5)
rm(list=ls())
library(data.table) # fread()
library(ggplot2) # nice boxplots
library(rpart) # tree models
library(rpart.plot) # nice tree graphs
library(glmnet) # logistic regression
library(randomForest) #random forest
library(e1071) # SVM
library(ROCR)		# ROC curves
library(crossval)   # model evaluation
library(rmarkdown)
data <- fread(file='plr.dataset.B.development.csv', header=T, sep="\t")
data <- as.data.frame(data)
features <- colnames(data[,-1])
str(data)
summary(data)
ids <- levels(factor(data$protein_id))
# dividing data into train test 90:10
set.seed(666)
train <- subset( data, data$protein_id %in% sample(ids, size=0.9*nrow(data)))
# dividing data into train test 90:10
set.seed(666)
train <- subset( data, data$protein_id %in% sample(ids, size=0.9*length(ids))
)
train <- subset( data, data$protein_id %in% sample(ids, size=0.9*length(ids)))
test <- data [ !(row.names(data) %in% row.names(train)), ]
levels(factor(train$protein_id))
levels(factor(test$protein_id))
load(".RData")
# best model no1 - Tuned Random Forest
forest.best <- randomForest(as.factor(class) ~ .,
data=data[sample(nrow(data)), -1],
mtry=14,
nodesize=30,
ntree=500)
library(data.table) # fread()
library(ggplot2) # nice boxplots
library(rpart) # tree models
library(rpart.plot) # nice tree graphs
library(randomForest) #random forest
library(e1071) # SVM
library(ROCR)		# ROC curves
library(crossval)   # model evaluation
library(rmarkdown) # report
# best model no1 - Tuned Random Forest
forest.best <- randomForest(as.factor(class) ~ .,
data=data[sample(nrow(data)), -1],
mtry=14,
nodesize=30,
ntree=500)
confusionMatrix(test$class, predict(forest.best, test, type="class"), "0")
diagnosticErrors(confusionMatrix(test$class, predict(forest.best, test, type="class"), "0"))[1]
blind.forest.pred <- predict(forest.best, blind[,-1], type="class")
blind <- fread(file='plr.dataset.B.test.blind.csv', header=T, sep="\t")
blind <- as.data.frame(blind)
blind.forest.pred <- predict(forest.best, blind[,-1], type="class")
fileConn<-file("model1-forest.txt")
writeLines(blind.forest.pred, fileConn)
blind.forest.pred[1:10]
as.character(blind.forest.pred[1:10])
writeLines(as.character(blind.forest.pred[1:10]), fileConn)
close(fileConn)
fileConn<-file("model1-forest.txt")
writeLines(as.character(blind.forest.pred), fileConn)
close(fileConn)
sum(blind.forest.pred)
sum(as.numeric(blind.forest.pred))
blind.forest.pred[1:10]
blind.forest.pred[1]+blind.forest.pred[2]
sum(as.vector(blind.forest.pred))
as.numeric(blind.forest.pred[1:10])
blind.forest.pred[1:10]
levels(factor(blind.forest.pred))
factor(blind.forest.pred)
length(blind.forest.pred)
length(blind.forest.pred[blind.forest.pred==0])
length(blind.forest.pred[blind.forest.pred==1])
# best model no2 - SVM tuned
SVM.best <- svm(as.factor(class) ~ .,
data = data[sample(nrow(data)), -1],
kernel = "radial",
gamma = 0.05,
cost = 2)
confusionMatrix(test$class, predict(SVM.best, test, type="class"), "0")
diagnosticErrors(confusionMatrix(test$class, predict(SVM.best, test, type="class"), "0"))[1]
blind.SVM.pred <- predict(SVM.best, blind[,-1], type="class")
fileConn<-file("model1-SVM.txt")
writeLines(blind.SVM.pred, fileConn)
writeLines(as.character(blind.SVM.pred), fileConn)
close(fileConn)
length(blind.SVM.pred[blind.SVM.pred==1])
blind.forest.pred==blind.SVM.pred
sum(blind.forest.pred==blind.SVM.pred)
sum(blind.forest.pred!=blind.SVM.pred)
table(blind.forest.pred, blind.SVM.pred)
rpart.plot(tree.pruned, extra=3)
SVM.conf <- confusionMatrix(test$class, predict(SVM.tuned, test, type="class"), "0")
SVM.conf <- confusionMatrix(test$class, predict(SVM.pruned, test, type="class"), "0")
SVM.conf
diagnosticErrors(SVM.conf)[1]
### t-tests
SVM.acc <- mean(crossSvmAcc)
SVM.acc
